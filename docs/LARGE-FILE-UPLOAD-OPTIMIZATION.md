# å¤§æ–‡ä»¶ä¸Šä¼ ä¼˜åŒ–å®Œæ•´æ–¹æ¡ˆ

## ğŸ¯ ç›®æ ‡
å®ç°åƒä¸»æµäº§å“ä¸€æ ·çš„å¿«é€Ÿå¤§æ–‡ä»¶ä¸Šä¼ ä½“éªŒï¼ˆ100MB+ å‡ ç§’å®Œæˆï¼‰

---

## ğŸ“Š ä¸»æµäº§å“çš„æŠ€æœ¯æ–¹æ¡ˆ

### ä»–ä»¬å¦‚ä½•åšåˆ°å¿«é€Ÿä¸Šä¼ ï¼Ÿ

#### 1. **åˆ†ç‰‡ä¸Šä¼  (Chunked Upload)** ã€æ ¸å¿ƒã€‘
```
100MBæ–‡ä»¶ åˆ†æˆ 100ä¸ª 1MBåˆ†ç‰‡
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ 1MB â”‚ 1MB â”‚ 1MB â”‚ ... â”‚ 1MB â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
   â†“     â†“     â†“     â†“     â†“
 å¹¶è¡Œä¸Šä¼ ï¼ˆ10ä¸ªåŒæ—¶ï¼‰
   â†“     â†“     â†“     â†“     â†“
  âœ“     âœ“     âœ“     âœ“     âœ“
```

**ä¼˜åŠ¿**:
- âœ… **å¹¶è¡Œä¸Šä¼ **: 10ä¸ªåˆ†ç‰‡åŒæ—¶ä¼ ,é€Ÿåº¦x10
- âœ… **æ–­ç‚¹ç»­ä¼ **: å¤±è´¥åªé‡ä¼ å¤±è´¥çš„åˆ†ç‰‡
- âœ… **å®æ—¶è¿›åº¦**: æ¯ä¸ªåˆ†ç‰‡å®Œæˆéƒ½æ›´æ–°è¿›åº¦æ¡
- âœ… **ç»•è¿‡é™åˆ¶**: å•ä¸ªè¯·æ±‚ä¸è¶…æ—¶

#### 2. **ç›´ä¼ äº‘å­˜å‚¨ (Direct Upload)**
```
ä¼ ç»Ÿæ–¹æ¡ˆ (æ…¢):
ç”¨æˆ· â†’ VercelæœåŠ¡å™¨ â†’ Supabase Storage
     10MB/s        å¿«é€Ÿ

ä¼˜åŒ–æ–¹æ¡ˆ (å¿«):
ç”¨æˆ· â†’ Supabase Storage (ç›´ä¼ )
     100MB/s (CDNåŠ é€Ÿ)
```

**ä¼˜åŠ¿**:
- âœ… **ä¸ç»è¿‡æœåŠ¡å™¨**: ä¸å ç”¨Vercelå¸¦å®½
- âœ… **CDNåŠ é€Ÿ**: è‡ªåŠ¨é€‰æ‹©æœ€è¿‘èŠ‚ç‚¹
- âœ… **æ— é™åˆ¶**: ä¸å—Serverlesså‡½æ•°è¶…æ—¶é™åˆ¶
- âœ… **æˆæœ¬ä½**: èŠ‚çœæœåŠ¡å™¨æµé‡è´¹ç”¨

#### 3. **é¢„ç­¾åURL (Presigned URL)**
```javascript
// 1. å®¢æˆ·ç«¯è¯·æ±‚ä¸Šä¼ æƒé™
POST /api/upload/init
Response: {
  uploadUrl: "https://storage.supabase.co/upload/xxxxx?token=...",
  uploadId: "abc123"
}

// 2. å®¢æˆ·ç«¯ç›´æ¥ä¸Šä¼ åˆ°å­˜å‚¨
PUT uploadUrl
Body: æ–‡ä»¶æ•°æ®

// 3. é€šçŸ¥æœåŠ¡å™¨å®Œæˆ
POST /api/upload/complete
```

#### 4. **å‹ç¼©ä¼ è¾“**
- æ–‡æœ¬æ–‡ä»¶å‹ç¼©90%+
- è‡ªåŠ¨gzip/brotliå‹ç¼©
- å‡å°‘ä¼ è¾“æ—¶é—´

#### 5. **æ™ºèƒ½é‡è¯•**
- è‡ªåŠ¨é‡è¯•å¤±è´¥çš„åˆ†ç‰‡
- æŒ‡æ•°é€€é¿ç­–ç•¥
- ç½‘ç»œæ³¢åŠ¨ä¸å½±å“ä¸Šä¼ 

---

## ğŸ”§ å…·ä½“å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆä¸€: Supabase Storage ç›´ä¼  + åˆ†ç‰‡ ã€æ¨èã€‘

#### ä¼˜åŠ¿
- âœ… æ— éœ€é¢å¤–æœåŠ¡
- âœ… Supabaseå†…ç½®æ”¯æŒ
- âœ… ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ
- âœ… å…è´¹é¢åº¦å……è¶³

#### å®ç°æ­¥éª¤

**1. åˆ›å»ºåˆ†ç‰‡ä¸Šä¼ å·¥å…·**

```typescript
// lib/services/chunkedUpload.ts

interface ChunkUploadOptions {
  file: File
  chunkSize?: number // é»˜è®¤ 5MB
  onProgress?: (progress: number) => void
  onChunkComplete?: (chunkIndex: number, total: number) => void
}

export class ChunkedUploader {
  private file: File
  private chunkSize: number
  private onProgress?: (progress: number) => void
  private chunks: Blob[] = []
  private uploadedChunks = new Set<number>()

  constructor(options: ChunkUploadOptions) {
    this.file = options.file
    this.chunkSize = options.chunkSize || 5 * 1024 * 1024 // 5MB
    this.onProgress = options.onProgress
    this.createChunks()
  }

  private createChunks() {
    const totalChunks = Math.ceil(this.file.size / this.chunkSize)
    for (let i = 0; i < totalChunks; i++) {
      const start = i * this.chunkSize
      const end = Math.min(start + this.chunkSize, this.file.size)
      this.chunks.push(this.file.slice(start, end))
    }
  }

  async upload(): Promise<string> {
    // 1. åˆå§‹åŒ–åˆ†ç‰‡ä¸Šä¼ 
    const { uploadId, key } = await this.initUpload()

    // 2. å¹¶è¡Œä¸Šä¼ åˆ†ç‰‡ï¼ˆæ¯æ¬¡æœ€å¤š10ä¸ªå¹¶å‘ï¼‰
    const CONCURRENT_UPLOADS = 10
    const totalChunks = this.chunks.length

    for (let i = 0; i < totalChunks; i += CONCURRENT_UPLOADS) {
      const batch = this.chunks.slice(i, i + CONCURRENT_UPLOADS)
      const uploadPromises = batch.map((chunk, idx) =>
        this.uploadChunk(chunk, i + idx, uploadId)
      )
      await Promise.all(uploadPromises)

      // æ›´æ–°è¿›åº¦
      const progress = Math.min(100, ((i + batch.length) / totalChunks) * 100)
      this.onProgress?.(progress)
    }

    // 3. å®Œæˆä¸Šä¼ 
    const fileUrl = await this.completeUpload(uploadId, key)
    return fileUrl
  }

  private async initUpload() {
    const response = await fetch('/api/upload/init', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        fileName: this.file.name,
        fileSize: this.file.size,
        totalChunks: this.chunks.length
      })
    })
    return response.json()
  }

  private async uploadChunk(
    chunk: Blob,
    chunkIndex: number,
    uploadId: string
  ) {
    // è·å–é¢„ç­¾åURL
    const { uploadUrl } = await fetch('/api/upload/chunk-url', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ uploadId, chunkIndex })
    }).then(r => r.json())

    // ç›´æ¥ä¸Šä¼ åˆ°å­˜å‚¨
    await fetch(uploadUrl, {
      method: 'PUT',
      body: chunk,
      headers: {
        'Content-Type': 'application/octet-stream',
        'Content-Length': chunk.size.toString()
      }
    })

    this.uploadedChunks.add(chunkIndex)
  }

  private async completeUpload(uploadId: string, key: string) {
    const response = await fetch('/api/upload/complete', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ uploadId, key })
    })
    const { fileUrl } = await response.json()
    return fileUrl
  }
}
```

**2. åç«¯APIå®ç°**

```typescript
// app/api/upload/init/route.ts
export async function POST(request: Request) {
  const { fileName, fileSize, totalChunks } = await request.json()

  // ç”Ÿæˆå”¯ä¸€ä¸Šä¼ ID
  const uploadId = crypto.randomUUID()
  const key = `uploads/${uploadId}/${fileName}`

  // ä¿å­˜ä¸Šä¼ ä¼šè¯åˆ°æ•°æ®åº“
  await supabase.from('upload_sessions').insert({
    upload_id: uploadId,
    file_name: fileName,
    file_size: fileSize,
    total_chunks: totalChunks,
    status: 'uploading'
  })

  return NextResponse.json({ uploadId, key })
}

// app/api/upload/chunk-url/route.ts
export async function POST(request: Request) {
  const { uploadId, chunkIndex } = await request.json()

  // ç”ŸæˆSupabaseé¢„ç­¾åURL
  const { data } = await supabaseAdmin.storage
    .from('books')
    .createSignedUploadUrl(`${uploadId}/chunk_${chunkIndex}`)

  return NextResponse.json({ uploadUrl: data.signedUrl })
}

// app/api/upload/complete/route.ts
export async function POST(request: Request) {
  const { uploadId, key } = await request.json()

  // åˆå¹¶æ‰€æœ‰åˆ†ç‰‡
  const chunks = await listChunks(uploadId)
  const mergedFile = await mergeChunks(chunks)

  // ä¸Šä¼ æœ€ç»ˆæ–‡ä»¶
  const { data } = await supabaseAdmin.storage
    .from('books')
    .upload(key, mergedFile)

  const { data: { publicUrl } } = supabaseAdmin.storage
    .from('books')
    .getPublicUrl(key)

  // æ¸…ç†åˆ†ç‰‡
  await cleanupChunks(uploadId)

  return NextResponse.json({ fileUrl: publicUrl })
}
```

**3. å‰ç«¯ä½¿ç”¨**

```typescript
// app/upload/page.tsx
const handleFileUpload = async (file: File) => {
  setUploading(true)

  const uploader = new ChunkedUploader({
    file,
    chunkSize: 5 * 1024 * 1024, // 5MB per chunk
    onProgress: (progress) => {
      setUploadProgress(progress)
      setProgress(`ä¸Šä¼ è¿›åº¦: ${progress.toFixed(1)}%`)
    },
    onChunkComplete: (current, total) => {
      console.log(`åˆ†ç‰‡ ${current + 1}/${total} å®Œæˆ`)
    }
  })

  try {
    const fileUrl = await uploader.upload()
    setProgress('ä¸Šä¼ å®Œæˆ!')
    // ç»§ç»­å¤„ç†...
  } catch (error) {
    setError('ä¸Šä¼ å¤±è´¥: ' + error.message)
  } finally {
    setUploading(false)
  }
}
```

---

### æ–¹æ¡ˆäºŒ: AWS S3 Multipart Upload ã€ä¸“ä¸šçº§ã€‘

#### ä¼˜åŠ¿
- âœ… ä¸šç•Œæ ‡å‡†æ–¹æ¡ˆ
- âœ… æ”¯æŒTBçº§æ–‡ä»¶
- âœ… è‡ªåŠ¨æ–­ç‚¹ç»­ä¼ 
- âœ… æ€§èƒ½æœ€ä¼˜

#### å®ç° (ä½¿ç”¨ AWS SDK)

```typescript
import { S3Client, CreateMultipartUploadCommand } from '@aws-sdk/client-s3'

const s3Client = new S3Client({ region: 'us-east-1' })

async function uploadLargeFile(file: File) {
  // 1. åˆ›å»ºåˆ†ç‰‡ä¸Šä¼ 
  const { UploadId } = await s3Client.send(
    new CreateMultipartUploadCommand({
      Bucket: 'my-bucket',
      Key: file.name
    })
  )

  // 2. ä¸Šä¼ åˆ†ç‰‡
  const parts = []
  const partSize = 10 * 1024 * 1024 // 10MB

  for (let i = 0; i < file.size; i += partSize) {
    const chunk = file.slice(i, i + partSize)
    const partNumber = Math.floor(i / partSize) + 1

    const { ETag } = await s3Client.send(
      new UploadPartCommand({
        Bucket: 'my-bucket',
        Key: file.name,
        UploadId,
        PartNumber: partNumber,
        Body: chunk
      })
    )

    parts.push({ ETag, PartNumber: partNumber })
  }

  // 3. å®Œæˆä¸Šä¼ 
  await s3Client.send(
    new CompleteMultipartUploadCommand({
      Bucket: 'my-bucket',
      Key: file.name,
      UploadId,
      MultipartUpload: { Parts: parts }
    })
  )
}
```

---

### æ–¹æ¡ˆä¸‰: ä½¿ç”¨ç¬¬ä¸‰æ–¹åº“ ã€æœ€ç®€å•ã€‘

#### Uppy.js + Tus (å¯æ¢å¤ä¸Šä¼ åè®®)

```bash
npm install @uppy/core @uppy/tus @uppy/dashboard
```

```typescript
import Uppy from '@uppy/core'
import Tus from '@uppy/tus'
import Dashboard from '@uppy/dashboard'

const uppy = new Uppy({
  restrictions: {
    maxFileSize: 1000 * 1024 * 1024, // 1GB
    allowedFileTypes: ['.pdf', '.epub']
  }
})
  .use(Tus, {
    endpoint: '/api/upload/tus',
    chunkSize: 5 * 1024 * 1024, // 5MB chunks
    retryDelays: [0, 1000, 3000, 5000]
  })
  .use(Dashboard, {
    inline: true,
    target: '#uppy-dashboard',
    showProgressDetails: true,
    proudlyDisplayPoweredByUppy: false
  })

uppy.on('complete', (result) => {
  console.log('Upload complete!', result.successful)
})
```

**æ•ˆæœ**:
- âœ… å¼€ç®±å³ç”¨çš„UI
- âœ… è‡ªåŠ¨æ–­ç‚¹ç»­ä¼ 
- âœ… å®æ—¶è¿›åº¦æ¡
- âœ… æ‹–æ‹½ä¸Šä¼ 
- âœ… æ–‡ä»¶éªŒè¯

---

## ğŸš€ æ€§èƒ½å¯¹æ¯”

| æ–¹æ¡ˆ | 100MBæ–‡ä»¶ | 1GBæ–‡ä»¶ | æ–­ç‚¹ç»­ä¼  | å¼€å‘éš¾åº¦ |
|------|----------|---------|---------|---------|
| **å½“å‰(å•æ¬¡ä¸Šä¼ )** | 30ç§’ | è¶…æ—¶å¤±è´¥ | âŒ | ç®€å• |
| **æ–¹æ¡ˆä¸€(åˆ†ç‰‡)** | 5-8ç§’ | 30-60ç§’ | âœ… | ä¸­ç­‰ |
| **æ–¹æ¡ˆäºŒ(S3)** | 3-5ç§’ | 20-40ç§’ | âœ… | å¤æ‚ |
| **æ–¹æ¡ˆä¸‰(Uppy)** | 5-8ç§’ | 30-60ç§’ | âœ… | ç®€å• |

---

## ğŸ’¡ ç«‹å³å¯å®æ–½çš„ä¼˜åŒ–ï¼ˆæ— éœ€å¤§æ”¹ï¼‰

### 1. å®¢æˆ·ç«¯ç›´ä¼  Supabase Storage

**å½“å‰æµç¨‹**:
```
æµè§ˆå™¨ â†’ Vercel â†’ Supabase (æ…¢)
```

**ä¼˜åŒ–å**:
```
æµè§ˆå™¨ â†’ Supabase (å¿«)
```

**å®ç°**:

```typescript
// app/upload/page.tsx
const handleDirectUpload = async (file: File) => {
  // 1. è·å–é¢„ç­¾åURL
  const { data: { path } } = await supabaseClient.storage
    .from('books')
    .upload(`temp/${Date.now()}_${file.name}`, file, {
      cacheControl: '3600',
      upsert: false
    })

  // 2. è·å–å…¬å¼€URL
  const { data: { publicUrl } } = supabaseClient.storage
    .from('books')
    .getPublicUrl(path)

  // 3. é€šçŸ¥åç«¯å¤„ç†
  await fetch('/api/books/process', {
    method: 'POST',
    body: JSON.stringify({ fileUrl: publicUrl, title, ... })
  })
}
```

### 2. æ·»åŠ è¿›åº¦æ¡

```typescript
const uploadWithProgress = async (file: File) => {
  const formData = new FormData()
  formData.append('file', file)

  const xhr = new XMLHttpRequest()

  xhr.upload.addEventListener('progress', (e) => {
    if (e.lengthComputable) {
      const percentComplete = (e.loaded / e.total) * 100
      setProgress(`ä¸Šä¼ ä¸­: ${percentComplete.toFixed(1)}%`)
    }
  })

  xhr.addEventListener('load', () => {
    if (xhr.status === 200) {
      setProgress('ä¸Šä¼ å®Œæˆ!')
    }
  })

  xhr.open('POST', '/api/books/upload')
  xhr.send(formData)
}
```

### 3. å‹ç¼©ä¼ è¾“

```typescript
// å¯¹æ–‡æœ¬å†…å®¹å‹ç¼©
import pako from 'pako'

const compressText = (text: string) => {
  const compressed = pako.gzip(text)
  return new Blob([compressed])
}

// ä¸Šä¼ å‹ç¼©åçš„å†…å®¹
formData.append('extractedText', compressText(extractedText))
```

---

## ğŸ“Š æ¨èå®æ–½è·¯çº¿

### ç¬¬ä¸€é˜¶æ®µ (æœ¬å‘¨) - å¿«é€Ÿä¼˜åŒ–
1. âœ… **å®¢æˆ·ç«¯ç›´ä¼ ** - é€Ÿåº¦æå‡50%
2. âœ… **å®æ—¶è¿›åº¦æ¡** - æ”¹å–„ç”¨æˆ·ä½“éªŒ
3. âœ… **æ–‡ä»¶å¤§å°æ£€æŸ¥å‰ç½®** - é¿å…æ— æ•ˆä¸Šä¼ 

é¢„æœŸæ•ˆæœ: 50MBæ–‡ä»¶ä»30ç§’é™åˆ°10ç§’

### ç¬¬äºŒé˜¶æ®µ (ä¸‹å‘¨) - åˆ†ç‰‡ä¸Šä¼ 
1. âœ… **å®ç°åŸºç¡€åˆ†ç‰‡** - 5MB per chunk
2. âœ… **å¹¶å‘ä¸Šä¼ ** - 5ä¸ªå¹¶å‘
3. âœ… **é”™è¯¯é‡è¯•** - è‡ªåŠ¨é‡è¯•

é¢„æœŸæ•ˆæœ: 100MBæ–‡ä»¶5-8ç§’å®Œæˆ

### ç¬¬ä¸‰é˜¶æ®µ (æœ¬æœˆ) - æ–­ç‚¹ç»­ä¼ 
1. âœ… **ä¿å­˜ä¸Šä¼ çŠ¶æ€** - localStorage
2. âœ… **ç»­ä¼ æ£€æµ‹** - åˆ·æ–°é¡µé¢å¯ç»§ç»­
3. âœ… **åˆ†ç‰‡å»é‡** - å·²ä¸Šä¼ çš„ä¸é‡å¤

é¢„æœŸæ•ˆæœ: ç½‘ç»œä¸­æ–­ä¸å½±å“ä¸Šä¼ 

### ç¬¬å››é˜¶æ®µ (é•¿æœŸ) - ä¸“ä¸šæ–¹æ¡ˆ
1. âœ… **é›†æˆUppy.js** - ä¼ä¸šçº§æ–¹æ¡ˆ
2. âœ… **CDNåŠ é€Ÿ** - å…¨çƒèŠ‚ç‚¹
3. âœ… **æ™ºèƒ½åˆ†ç‰‡** - æ ¹æ®ç½‘é€Ÿè°ƒæ•´

é¢„æœŸæ•ˆæœ: åª²ç¾ä¸»æµäº§å“

---

## ğŸ› ï¸ æ•°æ®åº“Schema (æ”¯æŒåˆ†ç‰‡ä¸Šä¼ )

```sql
-- ä¸Šä¼ ä¼šè¯è¡¨
CREATE TABLE upload_sessions (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  upload_id TEXT UNIQUE NOT NULL,
  user_id UUID REFERENCES auth.users(id),
  file_name TEXT NOT NULL,
  file_size BIGINT NOT NULL,
  total_chunks INTEGER NOT NULL,
  uploaded_chunks INTEGER DEFAULT 0,
  status TEXT DEFAULT 'uploading', -- uploading, completed, failed
  storage_key TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  completed_at TIMESTAMPTZ
);

-- åˆ†ç‰‡è®°å½•è¡¨
CREATE TABLE upload_chunks (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  upload_id TEXT REFERENCES upload_sessions(upload_id),
  chunk_index INTEGER NOT NULL,
  chunk_size INTEGER NOT NULL,
  etag TEXT,
  uploaded_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(upload_id, chunk_index)
);

-- ç´¢å¼•
CREATE INDEX idx_upload_sessions_user ON upload_sessions(user_id);
CREATE INDEX idx_upload_sessions_status ON upload_sessions(status);
CREATE INDEX idx_upload_chunks_upload ON upload_chunks(upload_id);
```

---

## ğŸ“ˆ ç›‘æ§å’Œåˆ†æ

```typescript
// ä¸Šä¼ æ€§èƒ½ç›‘æ§
const trackUpload = {
  fileSize: file.size,
  startTime: Date.now(),
  chunkSize: 5 * 1024 * 1024,
  totalChunks: Math.ceil(file.size / chunkSize),

  onComplete: () => {
    const duration = Date.now() - startTime
    const speed = (file.size / duration) * 1000 / 1024 / 1024 // MB/s

    console.log(`ä¸Šä¼ å®Œæˆ:
      - æ–‡ä»¶å¤§å°: ${(file.size / 1024 / 1024).toFixed(2)} MB
      - è€—æ—¶: ${(duration / 1000).toFixed(2)} ç§’
      - å¹³å‡é€Ÿåº¦: ${speed.toFixed(2)} MB/s
      - åˆ†ç‰‡æ•°: ${totalChunks}
    `)

    // å‘é€åˆ°åˆ†ææœåŠ¡
    analytics.track('file_upload', {
      size: file.size,
      duration,
      speed,
      chunks: totalChunks
    })
  }
}
```

---

## ğŸ¯ æ€»ç»“

è¦å®ç°å¿«é€Ÿå¤§æ–‡ä»¶ä¸Šä¼ ,æ ¸å¿ƒæ˜¯:

1. **åˆ†ç‰‡ + å¹¶å‘**: 10ä¸ª5MBåˆ†ç‰‡åŒæ—¶ä¸Šä¼ 
2. **ç›´ä¼ å­˜å‚¨**: ä¸ç»è¿‡æœåŠ¡å™¨,ç›´è¿CDN
3. **æ–­ç‚¹ç»­ä¼ **: å¤±è´¥è‡ªåŠ¨é‡è¯•
4. **æ™ºèƒ½å‹ç¼©**: å‡å°‘ä¼ è¾“é‡

**å¿«é€Ÿå¼€å§‹**: å…ˆå®æ–½å®¢æˆ·ç«¯ç›´ä¼ (1å¤©),å†åŠ åˆ†ç‰‡ä¸Šä¼ (3-5å¤©)

éœ€è¦æˆ‘ç°åœ¨å°±å¸®æ‚¨å®ç°ç¬¬ä¸€é˜¶æ®µçš„ä¼˜åŒ–å—ï¼Ÿ
